{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mlzMpsLb9y1J"
      },
      "outputs": [],
      "source": [
        "from os.path import isfile\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "lAE5dO1HcizG"
      },
      "outputs": [],
      "source": [
        "#Set htoe as true for translation from Hindi to Hnglish; \n",
        "#Set htoe as false for English to Hindi translation\n",
        "htoe = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cGSnWC1mfPNr"
      },
      "outputs": [],
      "source": [
        "if htoe:\n",
        "    tokenizer_one = pickle.load(open(\"tokenizer_hi\",\"rb\"))\n",
        "    tokenizer_two = pickle.load(open(\"tokenizer_en\",\"rb\"))\n",
        "else:\n",
        "    tokenizer_one = pickle.load(open(\"tokenizer_en\",\"rb\"))\n",
        "    tokenizer_two = pickle.load(open(\"tokenizer_hi\",\"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ZJZ0Aa6ZfYoP"
      },
      "outputs": [],
      "source": [
        "# Tweak the dataset params according to your needs\n",
        "\n",
        "MAX_LENGTH = 64 \n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktDQhz4OfbgN",
        "outputId": "31ccc6e9-422f-4f97-ca8b-469d2deba289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 690722\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset objects\n",
        "\n",
        "if htoe:\n",
        "    raw_data_one = pickle.load(open(\"raw_data_hi\",\"rb\"))\n",
        "    raw_data_two = pickle.load(open(\"raw_data_en\",\"rb\"))\n",
        "else:\n",
        "    raw_data_one = pickle.load(open(\"raw_data_en\",\"rb\"))\n",
        "    raw_data_two = pickle.load(open(\"raw_data_hi\",\"rb\"))\n",
        "\n",
        "print(\"Dataset size: {}\".format(len(raw_data_one)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "gDne60T4ffNz"
      },
      "outputs": [],
      "source": [
        "# Utility functions for data preprocessing\n",
        "\n",
        "def encode(lang1, lang2):\n",
        "  lang1 = [len(tokenizer_one.word_index)] + tokenizer_one.texts_to_sequences(\n",
        "      [lang1.numpy().decode(\"utf-8\")])[0] + [len(tokenizer_one.word_index)+1]\n",
        "\n",
        "  lang2 = [len(tokenizer_two.word_index)] + tokenizer_two.texts_to_sequences(\n",
        "      [lang2.numpy().decode(\"utf-8\")])[0] + [len(tokenizer_two.word_index)+1]\n",
        "  \n",
        "  return lang1, lang2\n",
        "\n",
        "def tf_encode(lang1, lang2):\n",
        "  result_one, result_two = tf.py_function(\n",
        "      encode, [lang1, lang2], [tf.int64, tf.int64])\n",
        "  result_one.set_shape([None])\n",
        "  result_two.set_shape([None])\n",
        "\n",
        "  return result_one, result_two\n",
        "\n",
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "loaW97a6ftuL"
      },
      "outputs": [],
      "source": [
        "# Obtain tf-data object from the dataset\n",
        "\n",
        "train_examples = tf.data.Dataset.from_tensor_slices((raw_data_one, raw_data_two)) \n",
        "\n",
        "train_preprocessed = (\n",
        "    train_examples \n",
        "    .map(tf_encode)\n",
        "    .filter(filter_max_length)\n",
        "    .cache()\n",
        "    .shuffle(BUFFER_SIZE))\n",
        "\n",
        "train_dataset = (train_preprocessed\n",
        "                 .padded_batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "lFfdtaN9fxEi"
      },
      "outputs": [],
      "source": [
        "# Define the vocab sizes\n",
        "\n",
        "input_vocab_size = len(tokenizer_one.word_index) + 2\n",
        "target_vocab_size = len(tokenizer_two.word_index) + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eIJwwQoKf5Xz"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained embeddings\n",
        "\n",
        "words_en, embeddings_en = pickle.load(\n",
        "    open('polyglot-en.pkl', 'rb'), encoding='latin1')\n",
        "words_hi, embeddings_hi = pickle.load(\n",
        "    open('polyglot-hi.pkl', 'rb'), encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "zV_wA9eyf5m-"
      },
      "outputs": [],
      "source": [
        "# English embedding matrix\n",
        "\n",
        "embeddings_index_en = {}\n",
        "if htoe:\n",
        "    word_index_en = tokenizer_two.word_index\n",
        "else:\n",
        "    word_index_en = tokenizer_one.word_index\n",
        "\n",
        "for i in range(len(words_en)):\n",
        "    embeddings_index_en[words_en[i].lower()] = embeddings_en[i]\n",
        "\n",
        "if htoe:\n",
        "    embedding_matrix_en = np.zeros((target_vocab_size, 64))\n",
        "else:\n",
        "    embedding_matrix_en = np.zeros((input_vocab_size, 64))\n",
        "\n",
        "for word, i in word_index_en.items():\n",
        "    embedding_vector = embeddings_index_en.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_en[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RqNOMm2pf8fF"
      },
      "outputs": [],
      "source": [
        "# Hindi embedding matrix\n",
        "\n",
        "embeddings_index_hi = {}\n",
        "if htoe:\n",
        "    word_index_hi = tokenizer_one.word_index\n",
        "else:\n",
        "    word_index_hi = tokenizer_two.word_index\n",
        "\n",
        "for i in range(len(words_hi)):\n",
        "    embeddings_index_hi[words_hi[i]] = embeddings_hi[i]\n",
        "\n",
        "if htoe:\n",
        "    embedding_matrix_hi = np.zeros((input_vocab_size, 64))\n",
        "else:\n",
        "    embedding_matrix_hi = np.zeros((target_vocab_size, 64))\n",
        "    \n",
        "for word, i in word_index_hi.items():\n",
        "    embedding_vector = embeddings_index_hi.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_hi[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "sqznmRpJgAgH"
      },
      "outputs": [],
      "source": [
        "if htoe:\n",
        "    embedding_matrix_one = embedding_matrix_hi\n",
        "    embedding_matrix_two = embedding_matrix_en\n",
        "else:\n",
        "    embedding_matrix_one = embedding_matrix_en\n",
        "    embedding_matrix_two = embedding_matrix_hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "syUtOkNhgCY1"
      },
      "outputs": [],
      "source": [
        "# Set the model Hyperparams\n",
        "\n",
        "num_layers = 6\n",
        "d_model = 64\n",
        "dff = 2048\n",
        "num_heads = 32\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "3TGni_aLgGEX"
      },
      "outputs": [],
      "source": [
        "# Utility functions for the model\n",
        "\n",
        "def positional_encoding(max_pos, d_model):\n",
        "    \"\"\" Returns the positional encoding for all positions\n",
        "\n",
        "    Args:\n",
        "        max_pos: (int) size of required positional embeddings equal to \n",
        "        the vocab size\n",
        "        d_model: (int) model size equal to the embedding size\n",
        "    \n",
        "    Returns:\n",
        "        pe: (tensor of type float32, shape = \n",
        "        (1, max_pos, d_model)) positional encodings of type float32\n",
        "    \"\"\"\n",
        "\n",
        "    theta = np.expand_dims(np.arange(max_pos), 1) / (np.power(10000, \n",
        "    (2 * np.expand_dims(np.arange(d_model), 0) // 2) / d_model))\n",
        "  \n",
        "    # sin(i) for all even i\n",
        "    theta[:, 0::2] = np.sin(theta[:, 0::2]) \n",
        "    \n",
        "    # cos(i) for all odd i\n",
        "    theta[:, 1::2] = np.cos(theta[:, 1::2]) \n",
        "    \n",
        "    pe = np.expand_dims(theta, 0)\n",
        "    \n",
        "    return tf.cast(pe, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    \"\"\" Creates a padding mask for the self attention layer in the decoder\n",
        "    \"\"\"\n",
        "\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    \n",
        "    # (batch_size, 1, 1, seq_len)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  \n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  \n",
        "  # (seq_len, seq_len)\n",
        "  return mask  \n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  # (..., seq_len_q, seq_len_k)\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  \n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  # (..., seq_len_q, seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  \n",
        "\n",
        "  # (..., seq_len_q, depth_v)\n",
        "  output = tf.matmul(attention_weights, v)  \n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "\n",
        "    # (batch_size, seq_len, dff)\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model)\n",
        "  ])\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "rMz83t5jgLzq"
      },
      "outputs": [],
      "source": [
        "# Define the Model layers\n",
        "\n",
        "# Multihead Attention keras layer\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is :\n",
        "    (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    # (batch_size, seq_len, d_model)\n",
        "    q = self.wq(q)  \n",
        "    k = self.wk(k)\n",
        "    v = self.wv(v)\n",
        "    \n",
        "    # (batch_size, num_heads, seq_len_q, depth)\n",
        "    q = self.split_heads(q, batch_size)\n",
        "\n",
        "    # (batch_size, num_heads, seq_len_k, depth)  \n",
        "    k = self.split_heads(k, batch_size)\n",
        "\n",
        "    # (batch_size, num_heads, seq_len_v, depth)\n",
        "    v = self.split_heads(v, batch_size)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  \n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights\n",
        "\n",
        "# Encoder keras Layer\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  \n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    \n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    out1 = self.layernorm1(x + attn_output)  \n",
        "    \n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.ffn(out1)  \n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    \n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  \n",
        "    \n",
        "    return out2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(\n",
        "        input_vocab_size, \n",
        "        d_model, \n",
        "        weights = [embedding_matrix_one], \n",
        "        trainable = False)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    x = self.embedding(x)  \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    # (batch_size, input_seq_len, d_model)\n",
        "    return x  \n",
        "\n",
        "# Decoder keras layer\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  \n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  \n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    \n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    out2 = self.layernorm2(attn2 + out1)  \n",
        "    \n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.ffn(out2)  \n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    \n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  \n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(\n",
        "        target_vocab_size, \n",
        "        d_model, \n",
        "        weights = [embedding_matrix_two], \n",
        "        trainable=False)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    # (batch_size, target_seq_len, d_model)\n",
        "    x = self.embedding(x) \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "MyobdaqGgSi3"
      },
      "outputs": [],
      "source": [
        "# Define the Model\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    # (batch_size, inp_seq_len, d_model)\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  \n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    final_output = self.final_layer(dec_output)  \n",
        "    \n",
        "    return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "sU9AXlefgVsv"
      },
      "outputs": [],
      "source": [
        "# Define the Learning Rate\n",
        "\n",
        "# Custom Learning rate scheduler\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "# create the optimizer object with the custom learning rate\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, \n",
        "    beta_1=0.9, \n",
        "    beta_2=0.98, \n",
        "    epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nW0aaZo5gYc-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the loss for the model\n",
        "\n",
        "# Create the required type of loss\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, \n",
        "    reduction='none')\n",
        "\n",
        "# Define how loss is calculated\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "# Create the loss and accuracy objects\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(\n",
        "    name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6yw9We9gfG-",
        "outputId": "66ba81df-7067-43c5-f620-ae150043decc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  transformer_htoe.weights.zip\n",
            "  inflating: transformer_htoe.weights.data-00000-of-00002  \n",
            "  inflating: transformer_htoe.weights.data-00001-of-00002  \n",
            "  inflating: transformer_htoe.weights.index  \n",
            "Archive:  transformer_etoh.weights.zip\n",
            "  inflating: transformer_etoh.weights.data-00000-of-00002  \n",
            "  inflating: transformer_etoh.weights.data-00001-of-00002  \n",
            "  inflating: transformer_etoh.weights.index  \n"
          ]
        }
      ],
      "source": [
        "# Create the model object with the necessary params\n",
        "\n",
        "# Unzip the weights\n",
        "\n",
        "!unzip -o transformer_htoe.weights.zip\n",
        "!unzip -o transformer_etoh.weights.zip\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "# Load any pre-trained weights (Comment out if retraining from scratch)\n",
        "\n",
        "if htoe:\n",
        "    transformer.load_weights('transformer_htoe.weights')\n",
        "else:\n",
        "    transformer.load_weights('transformer_etoh.weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "N5WAKkZ2gizr"
      },
      "outputs": [],
      "source": [
        "# Define training epochs\n",
        "\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Ab1FuJB2gs-f"
      },
      "outputs": [],
      "source": [
        "# Define the training step function\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "nY2xtz-4gtnO",
        "outputId": "7b82a91c-3d7c-4530-d9b7-4c278207594c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 3.5961 Accuracy 0.1077\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-368ce2d474a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Start training the model\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "  transformer.save_weights('transformer_{}.weights'.format(epoch + 1))\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for prediction\n",
        "\n",
        "MAX_LENGTH = 64 \n",
        "\n",
        "def preprocess_string(s):\n",
        "    ''' String preprocessing function\n",
        "\n",
        "    Args:\n",
        "        s: The string to be preprocessed\n",
        "    \n",
        "    Returns:\n",
        "        s: The preprocessed String\n",
        "    '''\n",
        "\n",
        "    if htoe:\n",
        "        s = re.sub(r'[a-zA-Z]', '', s) # Removes english chars from hindi text\n",
        "    s = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", s) # Removes text between braces\n",
        "    s = re.sub(r'([!.?।])', r' \\1', s) #Includes space between some characters\n",
        "    s = re.sub(r'\\s+', r' ', s) #Reduces multispace string to a single space\n",
        "    \n",
        "    return s\n",
        "\n",
        "def evaluate(inp_sentence):\n",
        "  start_token = [len(tokenizer_one.word_index)]\n",
        "  end_token = [len(tokenizer_one.word_index) + 1]\n",
        "  \n",
        "  inp_sentence = start_token + tokenizer_one.texts_to_sequences(\n",
        "      [inp_sentence])[0] + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  decoder_input = [len(tokenizer_two.word_index)]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(64):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == len(tokenizer_two.word_index)+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "def translate(sentence):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer_two.sequences_to_texts(\n",
        "      [[i.numpy()] for i in result if i < len(tokenizer_two.word_index)])  \n",
        "\n",
        "  return ' '.join(predicted_sentence)"
      ],
      "metadata": {
        "id": "_WIohmRuB6Ye"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter input sentence\n",
        "inp_str = \"क्या मैं आपकी मदद कर सकता हुँ  ?\"\n",
        "\n",
        "print(translate(preprocess_string(inp_str)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlY3KiX5B_dn",
        "outputId": "93b0505f-ea0d-4029-ab98-86d36e97f9a6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can i help you ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MUYm5pXmCByV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Codefiesta.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}